https://scontent-frt3-2.xx.fbcdn.net/v/t39.8562-6/79078865_2602377539850898_574457313268596736_n.pdf?_nc_cat=109&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=jOyoLQh8NDYAX9M_K1i&_nc_ht=scontent-frt3-2.xx&oh=00_AT-Vx_nuIaJLxCGKyAieC_4RQwT4HYzJknOYEk2c1lDdmA&oe=62D1CDDC

# A Roadmap towards Machine Intelligence #

The computational community has preferred to focus, in the last decades, on solving relatively narrow empirical problems that are important for specific applications, but do not address the overarching goal of developing general-purpose intelligent machines.

In this article, we propose an alternative approach:

- We first define the general characteristics we think intelligent machines should possess.

- We present a concrete roadmap to develop them in realistic, small steps.

Development of these steps is incrementally structured in such a way that, jointly, they should lead us close to the ultimate goal of implementing a powerful AI. Achieving the long-term goal of building an intelligent machine equipped with the desired features at once seems too difficult, we need to define intermediate targets that can lead us in the right direction.

## Ability to communicate ##

Any practical realization of an intelligent machine will have to communicate.

Natural language is by far the easiest and most powerful communication device we possess.

Communication is, by its very nature, interactive: The possibility to hold a conversation is crucial both to gather new information and to optimize its transmission. 

Language can also serve as an interface to perceptual components, and thus update the machine about its physical surroundings. For example, an object recognition system could transform raw pixel data into object labels, allowing the machine to "see" its real-life environment through a controlled-language modality.

We are not claiming that the machine should carry out its interal reasoning in a linguistic form: only that its input and output are linguistic in nature.

Interaction will likely play a central role, as the best course of action for the intelligent machine might involve entering a conversation with the requester.

## Ability to learn ##

It is uncontroversial that a machine supposed to be helping us in a variety of scenarios, many unforseen by its developers, should be endowed with the capability of learning. A machine that does not learn cannot adapt or modify itself based on experience, as it will react in the same way to a given situation for its whole lifetime.

Together with learning comes motivation. Since we want to develop machines that make themselves useful to humans, the motivation component should be directly controlled by users through the communication channel.

## A simulated ecosystem to educate communication-based intelligent machines ##

The environment must be challenging enough to force the machine to develop sophisticated learning strategies. At the same time, complexity should be manageable, i.e., a human put into a similar environment should not find it unreasonably difficult to learn to communicate and act within it.

The machine will need to be capable to extract the correct generalizations from just a few examples, at a rate comparable to human learners.

Just like for humans, problem solving should first be grounded in concrete tasks, to be later extended to more abstract scenarios by analogical means.

### High-level description of the ecosystem ###

#### Agents ####

- Learner (AI system)

- Teacher

- Environment

#### Interface channels ####

The learner experience is entirely defined by generic input and output channels. The Teacher, the Environment and any other language-endowed agent write to the input stream. Reward is also written to the input stream. The Learner writes to its output channel.

#### Reward ####

Like in realistic biological scenarios, reward is sparse, mostly being awarded after the Learner has accomplished some task. As intelligence grows, we expect the reward to become very sparse, with the Learner able to elaborate complex plans that are only rewarded on successful completion, and even displaying some degree of self-motivation. The Learner should be taught that short-term positive reward might lead to loss at a later stage, and that sometimes reward can be maximized by engaging in activities that in the short term provide no benefit.

Ideally the policies it acquires will include strategies such as curiosity that would lead it to continue to acquire new skills for its own sake.

#### Incremental structure ####

It is more productive to let the Learner discover its own optimal learning path by cycling multiple times through blocks of tasks, rather than forcing it to follow a rigid difficulty-based level sequence.

Just like during child education, the Learner must first take its baby steps, in which it is carefully trained to accomplish simple tasks such as learning to construct basic commands. However, for the Learner to have any hope to develop into a fully-functional intelligent machine, we need to aim for a "snow-balling" effect to soon take place, such that later tasks, despite being inherently more complex, will require a lot less explicit coaching, thanks to a combinatorial explosion in the background abilities the Learner can creatively compose.

#### Time off for exploration ####

Throughout the simulation, we foresee phases in which the Learner is free to interact with the Environment and the Teacher without a defined task. Systems should learn to exploit this time off for undirected exploration, that should in turn lead to better performance in active stages. Since curiosity is beneficial in many situations, such behaviour should naturally lead to higher later rewards, and thus be learnable.

### Early stages of the simulation ###

#### Associating language to actions ####

The Learner is encouraged to take notice of what happens in the Environment and associate the Teacher's language to states of the world.

#### Learning to generalize ####

By adding sufficient variety to the trials above, the Learner should start to get hold of the compositional nature of commands.

#### Understanding higher-level orders ####

The general teaching strategy is to provide sets of paired trials:

- In the first trial, the Teacher describes the task explicitly as a sequence of primitve actions, and gives the high-level name of the order.

- In the second trial, the Teacher issues an equivalent high-level order, and the Learner is rewarded if it goes through the same sequence as in the first trial.

#### Interactive communication ####

Kick-start interactive communication, so that the Learner ca be efficiently directed by the Teacher:

- In a first set of trials, the Learner is rewarded for repeating a how to request uttered by the Teacher, and following precise instructions produced by the Teacher in response to the request.

- Trials are interspersed with trials where the Learner is assigned a task it can in principle accomplish by random search, but taking the initiative by issuing a how to request and then following the precise directions provided by the Teacher will considerably speed up reward.

#### Algorithmic knowledge ####

After acquiring a bank of algorithms, the Learner should be able, in advanced stages of the simulation, to productively combine them in order to succeed in full-fledged novel missions that involve accomplishing a larger number of hierarchically-structured sub-goals.

## Towards the development of intelligent machines ##

While we do not have a concrete proposal yet about how exactly such machines should be implemented, we will discuss some of the properties and components we think are needed to support the desired functionalities.

### Types of learning ###