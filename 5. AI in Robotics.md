https://ai.facebook.com/blog/advancing-ai-by-teaching-robots-to-learn/

# Advancing AI by teaching robots to learn (Article) #

Robotics provides important opportunities for advancing artificial intelligence, because teaching machines to learn on their own in the physical world will help us develop more capable and flexible AI systems in other scenarios as well.

Doing this work means addressing the complexity inherent in using sophisticated physical mechanisms and conducting experiments in the real world, where the data is noisier, conditions are more variable and uncertain, and experiments have additional time constraints. These are not simple issues to address, but they offer useful test cases for AI.

Much of our work in robotics concentrates on self-supervision, in which systems learn directly from raw data so they can adapt to new tasks and new circumstances. To do this in robotics, we're advancing techniques such as model-based reinforcement learning (RL) to enable robots to teach themselves through trial and error using direct input from sensors.

The projects highlighted here show how we're using these self-supervised learning approaches to address some of the most essential challenges in this field: developing robots that can move around in and explore their surroundings and manipulate objects they encounter.

## Teaching robots to learn how to walk on their own ##

Our goal is to reduce the number of interactions the robot needs to learn to walk. The techniques we are researching, which include

- Bayesian optimization

- Model-based RL

are designed to be generalized to work with a variety of different robots and environments.

## Using curiosity to learn more effectively ##

Curiosity is a central motivation for learning in humans, and in our recent research done in collaboration with colleagues at New York University, we're applying this notion to improve how robots learn in the real world. "Curious" AI systems are rewarded for exploring and trying new things, as well as for accomplishing a specific goal.

Although previous similar systems typically explore their environment randomly, ours does it in a structured manner, seeking to satisfy its curiosity by learning about its surroundings and thereby reducing model uncertainty.

We explicitly optimize actions that resolve uncertainty. To generate higher rewards for actions that explore the uncertain parts of the dynamics model, we seek to include the variance of the models prediction into the reward function evaluation. The system is aware of its model uncertainty and optimizes action sequences to both maximize rewards and reduce that model uncertainty, making it better able to handle new tasks and conditions.

Our research has shown that seeking to resolve uncertainty can actually help the robot achieve a task even faster. Our model was also better able to generalize to new tasks and initial conditions.

This curiosity-driven behaviour can help the robot avoid pitfalls, such as getting trapped or stuck.

## Robotics: A long-term focus for AI research ##

Robotics research projects will help us build AI that can learn more efficiently and better generalize to new applications, even in noisy and highly complex environments such as the physical world.